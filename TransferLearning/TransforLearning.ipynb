{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x22267f33700>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "LAYERS = [ tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")]\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential(LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\divya\\anaconda\\envs\\mlclass\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 300)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 - 14s - loss: 1.5275 - accuracy: 0.5970 - val_loss: 0.9444 - val_accuracy: 0.7980 - 14s/epoch - 8ms/step\n",
      "Epoch 2/10\n",
      "1719/1719 - 7s - loss: 0.7465 - accuracy: 0.8287 - val_loss: 0.5868 - val_accuracy: 0.8596 - 7s/epoch - 4ms/step\n",
      "Epoch 3/10\n",
      "1719/1719 - 8s - loss: 0.5412 - accuracy: 0.8624 - val_loss: 0.4685 - val_accuracy: 0.8834 - 8s/epoch - 4ms/step\n",
      "Epoch 4/10\n",
      "1719/1719 - 8s - loss: 0.4591 - accuracy: 0.8771 - val_loss: 0.4104 - val_accuracy: 0.8940 - 8s/epoch - 5ms/step\n",
      "Epoch 5/10\n",
      "1719/1719 - 8s - loss: 0.4142 - accuracy: 0.8869 - val_loss: 0.3758 - val_accuracy: 0.9006 - 8s/epoch - 5ms/step\n",
      "Epoch 6/10\n",
      "1719/1719 - 8s - loss: 0.3851 - accuracy: 0.8938 - val_loss: 0.3525 - val_accuracy: 0.9052 - 8s/epoch - 5ms/step\n",
      "Epoch 7/10\n",
      "1719/1719 - 8s - loss: 0.3644 - accuracy: 0.8979 - val_loss: 0.3348 - val_accuracy: 0.9102 - 8s/epoch - 5ms/step\n",
      "Epoch 8/10\n",
      "1719/1719 - 8s - loss: 0.3485 - accuracy: 0.9022 - val_loss: 0.3209 - val_accuracy: 0.9138 - 8s/epoch - 5ms/step\n",
      "Epoch 9/10\n",
      "1719/1719 - 8s - loss: 0.3356 - accuracy: 0.9053 - val_loss: 0.3111 - val_accuracy: 0.9152 - 8s/epoch - 5ms/step\n",
      "Epoch 10/10\n",
      "1719/1719 - 8s - loss: 0.3251 - accuracy: 0.9077 - val_loss: 0.3016 - val_accuracy: 0.9170 - 8s/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\divya\\OneDrive\\Desktop\\Deep Learning\\Deep-Learning-\\TransforLearning\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"C:\\\\Users\\\\divya\\\\OneDrive\\\\Desktop\\\\DL\\\\Deep-Learning-\\\\TransforLearning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_full_mnist_model = tf.keras.models.load_model(\"C:\\\\Users\\\\divya\\\\OneDrive\\\\Desktop\\\\DL\\\\Deep-Learning-\\\\TransforLearning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 300)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "load_full_mnist_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_even_odd_labels(labels):\n",
    "    for idx, label in enumerate(labels):\n",
    "        labels[idx] = np.where(label % 2 == 0, 1 , 0)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten: True\n",
      "dense_1: True\n",
      "leaky_re_lu: True\n",
      "dense_2: True\n",
      "leaky_re_lu_1: True\n",
      "dense_3: True\n"
     ]
    }
   ],
   "source": [
    "# Check trainable or not:\n",
    "\n",
    "for layer in load_full_mnist_model.layers:\n",
    "    print(f\"{layer.name}: {layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now flatten: False\n",
      "Now dense_1: False\n",
      "Now leaky_re_lu: False\n",
      "Now dense_2: False\n",
      "Now leaky_re_lu_1: False\n"
     ]
    }
   ],
   "source": [
    "# make lower layer UN-trainable except the last layer:\n",
    "\n",
    "for layer in load_full_mnist_model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "    print(f\"Now {layer.name}: {layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.Sequential(load_full_mnist_model.layers[:-1])\n",
    "new_model.add(\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential_1',\n",
       " 'layers': [{'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 28, 28),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'flatten_input'}},\n",
       "  {'class_name': 'Flatten',\n",
       "   'config': {'name': 'flatten',\n",
       "    'trainable': False,\n",
       "    'batch_input_shape': (None, 28, 28),\n",
       "    'dtype': 'float32',\n",
       "    'data_format': 'channels_last'}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_1',\n",
       "    'trainable': False,\n",
       "    'dtype': 'float32',\n",
       "    'units': 300,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'LeakyReLU',\n",
       "   'config': {'name': 'leaky_re_lu',\n",
       "    'trainable': False,\n",
       "    'dtype': 'float32',\n",
       "    'alpha': 0.30000001192092896}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_2',\n",
       "    'trainable': False,\n",
       "    'dtype': 'float32',\n",
       "    'units': 100,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'LeakyReLU',\n",
       "   'config': {'name': 'leaky_re_lu_1',\n",
       "    'trainable': False,\n",
       "    'dtype': 'float32',\n",
       "    'alpha': 0.30000001192092896}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_4',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 1,\n",
       "    'activation': 'sigmoid',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten: False\n",
      "dense_1: False\n",
      "leaky_re_lu: False\n",
      "dense_2: False\n",
      "leaky_re_lu_1: False\n",
      "dense_4: True\n"
     ]
    }
   ],
   "source": [
    "# Check trainable or not:\n",
    "\n",
    "for layer in new_model.layers:\n",
    "    print(f\"{layer.name}: {layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\divya\\anaconda\\envs\\mlclass\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "new_model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bin, y_valid_bin, y_test_bin = update_even_odd_labels([y_train, y_valid, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 - 8s - loss: 1395.1573 - accuracy: 0.4914 - val_loss: -1.0346e+04 - val_accuracy: 0.1126 - 8s/epoch - 5ms/step\n",
      "Epoch 2/10\n",
      "1719/1719 - 7s - loss: 1353.1121 - accuracy: 0.4914 - val_loss: -1.0046e+04 - val_accuracy: 0.1126 - 7s/epoch - 4ms/step\n",
      "Epoch 3/10\n",
      "1719/1719 - 7s - loss: 1311.0701 - accuracy: 0.4914 - val_loss: -9.7459e+03 - val_accuracy: 0.1126 - 7s/epoch - 4ms/step\n",
      "Epoch 4/10\n",
      "1719/1719 - 6s - loss: 1269.0250 - accuracy: 0.4914 - val_loss: -9.4456e+03 - val_accuracy: 0.1126 - 6s/epoch - 4ms/step\n",
      "Epoch 5/10\n",
      "1719/1719 - 7s - loss: 1226.9795 - accuracy: 0.4914 - val_loss: -9.1453e+03 - val_accuracy: 0.1126 - 7s/epoch - 4ms/step\n",
      "Epoch 6/10\n",
      "1719/1719 - 7s - loss: 1184.9371 - accuracy: 0.4914 - val_loss: -8.8451e+03 - val_accuracy: 0.1126 - 7s/epoch - 4ms/step\n",
      "Epoch 7/10\n",
      "1719/1719 - 7s - loss: 1142.8914 - accuracy: 0.4914 - val_loss: -8.5448e+03 - val_accuracy: 0.1126 - 7s/epoch - 4ms/step\n",
      "Epoch 8/10\n",
      "1719/1719 - 8s - loss: 1100.8468 - accuracy: 0.4914 - val_loss: -8.2446e+03 - val_accuracy: 0.1126 - 8s/epoch - 4ms/step\n",
      "Epoch 9/10\n",
      "1719/1719 - 7s - loss: 1058.8011 - accuracy: 0.4914 - val_loss: -7.9443e+03 - val_accuracy: 0.1126 - 7s/epoch - 4ms/step\n",
      "Epoch 10/10\n",
      "1719/1719 - 5s - loss: 1016.7587 - accuracy: 0.4914 - val_loss: -7.6441e+03 - val_accuracy: 0.1126 - 5s/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "new_history = new_model.fit(X_train, y_train_bin, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid_bin), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step - loss: 1013.7282 - accuracy: 0.4926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1013.7282104492188, 0.4925999939441681]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.evaluate(X_test, y_test_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7, 2, 1], dtype=uint8), array([0, 1, 0]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_test[:3], y_test_bin[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 294ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('mlclass')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69e3fa51ccf1797c2a3cbb4fbdd0eaecb4118d5b3e2d3047b67b1c56f2436560"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
